###########
###Libraries
###########
library(lactcurves)
library(dplyr)
library(polynom)
library(orthopolynom)
library(splines)
library(quantreg)
library(minpack.lm)
library(nlme)
library(tidyr)
library(ggplot2)
library(ggpmisc)
library(scales)
library(ggridges)
library(BMA)
library(lmtest)
library(car)
library(parameters)
library(lsr)
library(reshape2)
library(viridis)
###########

#####Setting work directory
setwd("~/Documents/UniLeon/projetos/Resilience_heatStress_Sheep/lactations_ASSAF_Ruth/")


source("functions_ensemble_models/GetLacModelsMetrics.R")
source("functions_ensemble_models/LacCurveFit.R")
source("functions_ensemble_models/ModelsLac.R")
source("functions_ensemble_models/RidgeModels.R")
source("functions_ensemble_models/ModelRankRange.R")
source("functions_ensemble_models/PlotWeightLac.R")
source("functions_ensemble_models/CosSquaredWeight.R")
source("functions_ensemble_models/VarWeight.R")
source("functions_ensemble_models/BMAweight.R")
source("functions_ensemble_models/HetBMAWeight.R")
source("functions_ensemble_models/bma_likelihood.R")
source("functions_ensemble_models/compute_bma_prediction.R")
source("functions_ensemble_models/estimate_bma_params_scemua.R")
source("functions_ensemble_models/metropolis_step.R")
source("functions_ensemble_models/initialize_population.R")
source("functions_ensemble_models/BMAweight_gamma.R")
source("functions_ensemble_models/bma_likelihood_gamma.R")


#####Loading lactation database

db.lac<-read.table("new_lactation_data/Database_all_Lacs_31_01_25.txt", h=T, sep="\t")

db.lac<-db.lac[which(db.lac$More_1_Lac=="1_Lac"),]

out.indID<-LacCurveFit(data=db.lac,ID="CodGen",trait="Produccion_Final_Dia",dim="DIM_2", alpha = 0.1)

out.indID.subModels<-LacCurveFit(data=db.lac,ID="CodGen",trait="Produccion_Final_Dia",dim="DIM_2", alpha = 0.1,models = c("DiG", "DiGpw","cubsplin5","wilminkPop", "qntReg", "Legpol4Poppe"))


RidgeModels(out.indID,metric="AIC_rank")


weight.mod<-out.indID.subModels$models_weight
weight.mod<-do.call(rbind, weight.mod)
weight.mod<-as.data.frame(weight.mod)

mean.aic<-aggregate(weight.mod$AIC, by=list(weight.mod$Model),FUN=mean)

mean.aic[order(mean.aic$x),]

###Best model in average cubsplin5
best.avg.model<-lapply(seq_along(out.indID$models_weight), function(i) {
  
  tmp.weight<-out.indID$models_weight[[i]]
  
  tmp.weight<-tmp.weight[which(tmp.weight$Model=="qntReg"),"AIC"]
  
  out.weight<-data.frame(Model="qntReg",AIC=tmp.weight,ID=names(out.indID$models_weight[i]))
  
})
best.avg.model <- do.call(rbind, best.avg.model)
best.avg.model <- as.data.frame(best.avg.model)

###Best individual model
best.ind.model<-lapply(seq_along(out.indID$models_weight), function(i) {
  
  tmp.weight<-out.indID$models_weight[[i]]
  
  tmp.weight<-tmp.weight[order(tmp.weight$AIC),]
  
  out.weight<-data.frame(Model=tmp.weight$Model[1],AIC=tmp.weight$AIC[1],ID=names(out.indID$models_weight[i]))
  
})
best.ind.model <- do.call(rbind, best.ind.model)
best.ind.model <- as.data.frame(best.ind.model)




##Fitting the best average model and each individual best model for each animal
fit.function<-function(ID,best.avg.model,best.ind.model,out.indID){
  
  
  sel.model<-out.indID$converged_models[[ID]]
  
  sel.model.avg<-sel.model[["cubsplin5"]]
  
  sel.model.best<-sel.model[best.ind.model[which(best.ind.model$ID==ID),"Model"]]
  
  if (!is.null(sel.model.avg)) {
    
    # Predict using the best model  
    pred.val.avg <- predict(sel.model.avg)
    
    df<- out.indID$production[[ID]]
    
    # db.pred.avg.tmp<-data.frame(ID=id,Pred=pred.val.avg,real=df$Produccion_Final_Dia, quant=p,method="Avg_Best")
    
  }
  
  sel.model<-out.indID$converged_models[[ID]]
  
  sel.model.best.id<-best.ind.model[which(best.ind.model$ID==ID),"Model"]
  
  sel.model.best<-sel.model[[sel.model.best.id]]
  
  pred.val.best <- predict(sel.model.best)
  
  
  ###Creating db
  tmp.out<-data.frame(ID=ID,Prod_real=df$Produccion_Final_Dia,pred_best=pred.val.best, pred_avg=pred.val.avg,DIM_2=df$DIM_2)
  
  return(tmp.out)
  
  
}


fit.models<-lapply(seq_along(out.indID$models_weight), function(i) {
  
  print(paste(i, "out", length(out.indID$models_weight)))
  
  IDs<-names(out.indID$models_weight[i])
  
  fit.out<-fit.function(ID=IDs,best.avg.model,best.ind.model,out.indID)
  
  return(fit.out)
  
})

fit.models <- do.call(rbind, fit.models)
fit.models <- as.data.frame(fit.models)


####Getting animals in the worse quantiles for the AIC dist in the best average model and in the individual model

###Define intervals
int.perc<-seq(0.80,0.95,0.05)
db.quantil<-NULL
for(p in int.perc){
  
  print(p)
  
  sel.ids.avg<-best.avg.model[which(best.avg.model$AIC>=quantile(best.avg.model$AIC,p)),"ID"]
  
  sel.ids.best<-best.ind.model[which(best.ind.model$AIC>=quantile(best.ind.model$AIC,p)),"ID"]
    
    ###Creating db
    tmp.out<-data.frame(ID=c(sel.ids.avg,sel.ids.best),avg_best=c(rep("Average",length(sel.ids.avg)),rep("Best_ind",length(sel.ids.best))), quant=p)
    
    db.quantil<-rbind(db.quantil,tmp.out)
  
}


source("functions_ensemble_models/resilience_indicators.R")

res.best.avg<-resilience_indicators(fit.models, 
                                      dim_filter_range = c(1, 7, 203, 210), 
                                      outlier_sd_threshold = 4,
                                      weight="pred_avg",trait="Prod_real",ID_col="ID")


res.best.avg<-res.best.avg$ri_filtrados
res.best.avg$Method<-"Average"


res.best.ind<-resilience_indicators(fit.models, 
                                    dim_filter_range = c(1, 7, 203, 210), 
                                    outlier_sd_threshold = 4,
                                    weight="pred_best",trait="Prod_real",ID_col="ID")


res.best.ind<-res.best.ind$ri_filtrados
res.best.ind$Method<-"Best_Ind"


out.indID.df <- do.call(rbind, out.indID$production)
out.indID.df <- as.data.frame(out.indID.df)
out.indID.df$CodGen <- substr(rownames(out.indID.df), 1, 9)


res.AIC.weight<-resilience_indicators(out.indID.df, 
                      dim_filter_range = c(1, 7, 203, 210), 
                      outlier_sd_threshold = 4,
                      weight="weight_AIC",
                      trait="Produccion_Final_Dia",ID_col="CodGen")

res.AIC.weight<-res.AIC.weight$ri_filtrados
res.AIC.weight$Method<-"AIC"

res.BIC.weight<-resilience_indicators(out.indID.df, 
                                      dim_filter_range = c(1, 7, 203, 210), 
                                      outlier_sd_threshold = 4,
                                      weight="weight_BIC",
                                      trait="Produccion_Final_Dia",ID_col="CodGen")

res.BIC.weight<-res.BIC.weight$ri_filtrados
res.BIC.weight$Method<-"BIC"

res.SMA<-resilience_indicators(out.indID.df, 
                                      dim_filter_range = c(1, 7, 203, 210), 
                                      outlier_sd_threshold = 4,
                                      weight="SMA",
                               trait="Produccion_Final_Dia",ID_col="CodGen")
res.SMA<-res.SMA$ri_filtrados
res.SMA$Method<-"SMA"

res.BAM.weight<-resilience_indicators(out.indID.df, 
                                      dim_filter_range = c(1, 7, 203, 210), 
                                      outlier_sd_threshold = 4,
                                      weight="weight_BAM",
                                      trait="Produccion_Final_Dia",ID_col="CodGen")
res.BAM.weight<-res.BAM.weight$ri_filtrados
res.BAM.weight$Method<-"BMA"

res.BAM_Het.weight<-resilience_indicators(out.indID.df, 
                                      dim_filter_range = c(1, 7, 203, 210), 
                                      outlier_sd_threshold = 4,
                                      weight="BAM_Het",
                                      trait="Produccion_Final_Dia",ID_col="CodGen")
res.BAM_Het.weight<-res.BAM_Het.weight$ri_filtrados
res.BAM_Het.weight$Method<-"BAM_Het"

res.CosSquared.weight<-resilience_indicators(out.indID.df, 
                                          dim_filter_range = c(1, 7, 203, 210), 
                                          outlier_sd_threshold = 4,
                                          weight="weight_CosSquared",
                                          trait="Produccion_Final_Dia",ID_col="CodGen")
res.CosSquared.weight<-res.CosSquared.weight$ri_filtrados
res.CosSquared.weight$Method<-"CosSquared"



merged.res<-rbind(res.best.avg, res.best.ind,res.AIC.weight,res.BIC.weight,res.SMA,res.BAM.weight,res.BAM_Het.weight,res.CosSquared.weight)

merged.res<-as.data.frame(merged.res)

# Reshape data to long format
df_long <- merged.res %>%
  pivot_longer(cols = c(log_varianza, autocorrelacion_lag1, skewness),
               names_to = "Variable",
               values_to = "Value")

# Plotting the boxplots
ggplot(df_long, aes(x = Variable, y = Value, fill = Method)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(x = "Variables", y = "Values", title = "Boxplots of Different Variables by Method") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_brewer(palette = "Set2")


ids.95.avg<-db.quantil[which(db.quantil$avg_best=="Average" & db.quantil$quant==0.95),"ID"]

ids.95.best<-db.quantil[which(db.quantil$avg_best=="Best_ind" & db.quantil$quant==0.95),"ID"]

ids.90.avg<-db.quantil[which(db.quantil$avg_best=="Average" & db.quantil$quant==0.90),"ID"]

ids.90.best<-db.quantil[which(db.quantil$avg_best=="Best_ind" & db.quantil$quant==0.90),"ID"]

ggplot(df_long[which(df_long$CodGen%in%ids.90.best & df_long$Variable=="log_varianza"),], aes(x = Method, y = Value)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(x = "Variables", y = "Values", title = "log_varianza 10% worse AIC best individual") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_brewer(palette = "Set2")

aggregate(merged.res[which(merged.res$CodGen%in%ids.95.avg),"log_varianza"], by=list(merged.res[which(merged.res$CodGen%in%ids.95.avg),"Method"]),FUN=summary)




ids.shared<-intersect(merged.res[which(merged.res$Method=="Best_Ind"),"CodGen"], merged.res[which(merged.res$Method=="BMA"),"CodGen"])

ids.shared<-ids.shared[ids.shared%in%ids.95.best]

##########
#####Skewness
##########

# Check normality of differences for Log Variance
autocorr_diff <- merged.res[which(merged.res$Method=="Average" & merged.res$CodGen%in%ids.shared),"skewness"] - merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"skewness"]

shapiro.test(autocorr_diff)


autocorr_avg<-merged.res[which(merged.res$Method=="Average" & merged.res$CodGen%in%ids.shared),"skewness"]

names(autocorr_avg)<-merged.res[which(merged.res$Method=="Average" & merged.res$CodGen%in%ids.shared),"CodGen"]


autocorr_aic<-merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"skewness"]

names(autocorr_aic)<-merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"CodGen"]

autocorr_avg<-autocorr_avg[ids.shared]

autocorr_aic<-autocorr_aic[ids.shared]


# Example for Autocorrelation
wilcox.test(autocorr_avg, autocorr_aic, paired = TRUE)


cohensD(autocorr_avg, autocorr_aic)


autocorr_diff <- autocorr_avg-autocorr_aic
mean_diff <- mean(autocorr_diff)
ci <- t.test(autocorr_diff)$conf.int

mean_diff
ci


##########
#####Autocorrelation
##########

# Check normality of differences for Log Variance
autocorr_diff <- merged.res[which(merged.res$Method=="Best_Ind" & merged.res$CodGen%in%ids.shared),"autocorrelacion_lag1"] - merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"autocorrelacion_lag1"]

shapiro.test(autocorr_diff)


autocorr_avg<-merged.res[which(merged.res$Method=="Best_Ind" & merged.res$CodGen%in%ids.shared),"autocorrelacion_lag1"]

names(autocorr_avg)<-merged.res[which(merged.res$Method=="Best_Ind" & merged.res$CodGen%in%ids.shared),"CodGen"]


autocorr_aic<-merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"autocorrelacion_lag1"]

names(autocorr_aic)<-merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"CodGen"]

autocorr_avg<-autocorr_avg[ids.shared]

autocorr_aic<-autocorr_aic[ids.shared]


# Example for Autocorrelation
wilcox.test(autocorr_avg, autocorr_aic, paired = TRUE)


cohensD(autocorr_avg, autocorr_aic)


autocorr_diff <- autocorr_avg-autocorr_aic
mean_diff <- mean(autocorr_diff)
ci <- t.test(autocorr_diff)$conf.int

mean_diff
ci


#############
#####Log variance
############
# Check normality of differences for Log Variance
log_var_diff <- merged.res[which(merged.res$Method=="Average" & merged.res$CodGen%in%ids.shared),"log_varianza"] - merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"log_varianza"]

shapiro.test(log_var_diff)


log_var_avg<-merged.res[which(merged.res$Method=="Average" & merged.res$CodGen%in%ids.shared),"log_varianza"]

names(log_var_avg)<-merged.res[which(merged.res$Method=="Average" & merged.res$CodGen%in%ids.shared),"CodGen"]


log_var_aic<-merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"log_varianza"]

names(log_var_aic)<-merged.res[which(merged.res$Method=="BMA" & merged.res$CodGen%in%ids.shared),"CodGen"]

log_var_avg<-log_var_avg[ids.shared]

log_var_aic<-log_var_aic[ids.shared]


# Example for Autocorrelation
wilcox.test(log_var_avg, log_var_aic, paired = TRUE)


cohensD(log_var_avg, log_var_aic)


log_var_diff <- log_var_avg-log_var_aic
mean_diff <- mean(log_var_diff)
ci <- t.test(log_var_diff)$conf.int

mean_diff
ci


###########
####Rank correlation
#########

intersec.ids<-intersect(merged.res[which(merged.res$Method=="AIC"),"CodGen"],merged.res[which(merged.res$Method=="Average"),"CodGen"])

ids.95.avg

####Log variance

log.var.avg.all<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="Average"),"log_varianza"]
names(log.var.avg.all)<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="Average"),"CodGen"]
log.var.avg.all<-log.var.avg.all[intersec.ids]


log.var.aic.all<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="AIC"),"log_varianza"]
names(log.var.aic.all)<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="AIC"),"CodGen"]
log.var.aic.all<-log.var.aic.all[intersec.ids]


db.cor.logvar<-data.frame(ID=c(names(log.var.avg.all),names(log.var.avg.all[ids.95.avg]),names(log.var.avg.all[ids.90.avg]),names(log.var.aic.all),names(log.var.aic.all[ids.95.best]),names(log.var.aic.all[ids.90.best])),
                          logvar=c(log.var.avg.all,log.var.avg.all[ids.95.avg],log.var.avg.all[ids.90.avg],log.var.aic.all,log.var.aic.all[ids.95.best],log.var.aic.all[ids.90.best]),
                          Method=c(rep("Average",length(c(names(log.var.avg.all),names(log.var.avg.all[ids.95.avg]),names(log.var.avg.all[ids.90.avg])))),
                                   rep("AIC",length(c(names(log.var.aic.all),names(log.var.aic.all[ids.95.best]),names(log.var.aic.all[ids.90.best]))))),
                          Data=c(rep("All",length(names(log.var.avg.all))), rep("95%_AIC_avg",length(names(log.var.avg.all[ids.95.avg]))), rep("90%_AIC_avg",length(names(log.var.avg.all[ids.90.avg]))), rep("All",length(names(log.var.avg.all))),rep("95%_AIC_best",length(names(log.var.avg.all[ids.95.best]))),rep("90%_AIC_best",length(names(log.var.avg.all[ids.90.best]))))
)


# Combine Method and Data into a group label
data <- db.cor.logvar %>%
  mutate(Group = paste(Method, Data, sep = "_"))

# Pivot data to wide format
pivot_data <- data %>%
  select(ID, Group, logvar) %>%
  pivot_wider(names_from = Group, values_from = logvar)

# Get group names
group_names <- colnames(pivot_data)[-1]  # Exclude 'ID'

# Initialize an empty matrix for Kendall's tau
tau_matrix <- matrix(NA, nrow = length(group_names), ncol = length(group_names))
rownames(tau_matrix) <- group_names
colnames(tau_matrix) <- group_names

# Fill the matrix with Kendall's tau values
for (i in 1:(length(group_names))) {
  for (j in i:length(group_names)) {
    if (i == j) {
      tau_matrix[i, j] <- 1  # Correlation of a group with itself
    } else {
      # Select data for the pair
      pair_data <- pivot_data %>%
        select(all_of(group_names[i]), all_of(group_names[j])) %>%
        na.omit()
      
      if (nrow(pair_data) > 1) {
        # Calculate Kendall's tau
        tau_value <- cor(pair_data[[1]], pair_data[[2]], method = "kendall")
        tau_matrix[i, j] <- tau_value
        tau_matrix[j, i] <- tau_value  # Symmetric matrix
      }
    }
  }
}

# Melt the matrix into long format for ggplot2
tau_long <- melt(tau_matrix, varnames = c("Group1", "Group2"), value.name = "Kendall_Tau")

# Plot the heatmap
ggplot(tau_long, aes(x = Group1, y = Group2, fill = Kendall_Tau)) +
  geom_tile(color = "white") +
  
  scale_fill_gradient2(
    low = "blue",       # For negative correlation
    mid = "white",      # Neutral (zero correlation)
    high = "red",       # For positive correlation
    midpoint = 0,       # Set zero correlation to white
    limits = c(-1, 1),  # Define the scale limits
    na.value = "grey90" # Color for NA values
  ) +
  geom_text(aes(label = round(Kendall_Tau, 3)), color = "black", size = 4) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(size = 10),
        panel.grid = element_blank()) +
  labs(title = "Kendall's Tau Correlation Matrix Log variance", x = "Group", y = "Group", fill = "Tau")


# Kendall's tau correlation
kendall_corr_logVar.all <- cor.test(log.var.aic.all,log.var.avg.all, method = "kendall")

kendall_corr_logVar.all

kendall_corr_logVar.95 <- cor.test(log.var.aic.all[ids.95.avg], log.var.avg.all[ids.95.avg], method = "kendall")

kendall_corr_logVar.95

plot_data <- data.frame(CodGen=rep(names(log.var.avg.all[ids.95.avg]),2),logvar=c(log.var.avg.all[ids.95.avg],log.var.aic.all[ids.95.avg]),Method=c(rep("Average",length(log.var.avg.all[ids.95.avg])),rep("AIC",length(log.var.avg.all[ids.95.avg]))))

# Paired line plot
ggplot(plot_data, aes(x = Method, y = logvar, group = CodGen)) +
  geom_line(alpha = 0.8, color = "gray") +
  geom_point(aes(color = Method), size = 3) +
  labs(title = "Paired Comparison of Log(Variance): Best Average vs Ensemble",
       y = "Log Variance", x = "") +
  theme_minimal()


####autocorrelation
auto.avg.all<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="Average"),"autocorrelacion_lag1"]
names(auto.avg.all)<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="Average"),"CodGen"]
auto.avg.all<-auto.avg.all[intersec.ids]


auto.aic.all<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="AIC"),"autocorrelacion_lag1"]
names(auto.aic.all)<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="AIC"),"CodGen"]
auto.aic.all<-auto.aic.all[intersec.ids]


db.cor.auto<-data.frame(ID=c(names(auto.avg.all),names(auto.avg.all[ids.95.avg]),names(auto.avg.all[ids.90.avg]),names(auto.aic.all),names(auto.aic.all[ids.95.best]),names(auto.aic.all[ids.90.best])),
                          logvar=c(auto.avg.all,auto.avg.all[ids.95.avg],auto.avg.all[ids.90.avg],auto.aic.all,auto.aic.all[ids.95.best],auto.aic.all[ids.90.best]),
                          Method=c(rep("Average",length(c(names(auto.avg.all),names(auto.avg.all[ids.95.avg]),names(auto.avg.all[ids.90.avg])))),
                                   rep("AIC",length(c(names(auto.aic.all),names(auto.aic.all[ids.95.best]),names(auto.aic.all[ids.90.best]))))),
                          Data=c(rep("All",length(names(auto.avg.all))), rep("95%_AIC_avg",length(names(auto.avg.all[ids.95.avg]))), rep("90%_AIC_avg",length(names(auto.avg.all[ids.90.avg]))), rep("All",length(names(auto.avg.all))),rep("95%_AIC_best",length(names(auto.avg.all[ids.95.best]))),rep("90%_AIC_best",length(names(auto.avg.all[ids.90.best]))))
                          )

# Combine Method and Data into a group label
data <- db.cor.auto %>%
  mutate(Group = paste(Method, Data, sep = "_"))

# Pivot data to wide format
pivot_data <- data %>%
  select(ID, Group, logvar) %>%
  pivot_wider(names_from = Group, values_from = logvar)

# Get group names
group_names <- colnames(pivot_data)[-1]  # Exclude 'ID'

# Initialize an empty matrix for Kendall's tau
tau_matrix <- matrix(NA, nrow = length(group_names), ncol = length(group_names))
rownames(tau_matrix) <- group_names
colnames(tau_matrix) <- group_names

# Fill the matrix with Kendall's tau values
for (i in 1:(length(group_names))) {
  for (j in i:length(group_names)) {
    if (i == j) {
      tau_matrix[i, j] <- 1  # Correlation of a group with itself
    } else {
      # Select data for the pair
      pair_data <- pivot_data %>%
        select(all_of(group_names[i]), all_of(group_names[j])) %>%
        na.omit()
      
      if (nrow(pair_data) > 1) {
        # Calculate Kendall's tau
        tau_value <- cor(pair_data[[1]], pair_data[[2]], method = "kendall")
        tau_matrix[i, j] <- tau_value
        tau_matrix[j, i] <- tau_value  # Symmetric matrix
      }
    }
  }
}

# Melt the matrix into long format for ggplot2
tau_long <- melt(tau_matrix, varnames = c("Group1", "Group2"), value.name = "Kendall_Tau")

# Plot the heatmap
ggplot(tau_long, aes(x = Group1, y = Group2, fill = Kendall_Tau)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "blue",       # For negative correlation
    mid = "white",      # Neutral (zero correlation)
    high = "red",       # For positive correlation
    midpoint = 0,       # Set zero correlation to white
    limits = c(-1, 1),  # Define the scale limits
    na.value = "grey90" # Color for NA values
  ) +
  geom_text(aes(label = round(Kendall_Tau, 2)), color = "black", size = 4) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(size = 10),
        panel.grid = element_blank()) +
  labs(title = "Kendall's Tau Correlation Matrix lag-one autocor", x = "Group", y = "Group", fill = "Tau")


# Kendall's tau correlation
kendall_corr_auto.all <- cor.test(auto.aic.all,auto.avg.all, method = "kendall")

kendall_corr_auto.all

kendall_corr_auto.95 <- cor.test(auto.aic.all[ids.95.avg], auto.avg.all[ids.95.avg], method = "kendall")

kendall_corr_auto.95


plot_data <- data.frame(CodGen=rep(names(auto.avg.all[ids.95.avg]),2),auto=c(auto.avg.all[ids.95.avg],auto.aic.all[ids.95.avg]),Method=c(rep("Average",length(auto.avg.all[ids.95.avg])),rep("AIC",length(auto.aic.all[ids.95.avg]))))

# Paired line plot
ggplot(plot_data, aes(x = Method, y = auto, group = CodGen)) +
  geom_line(alpha = 0.8, color = "gray") +
  geom_point(aes(color = Method), size = 3) +
  labs(title = "Paired Comparison of Lag-one autocorrelation: Best Average vs Ensemble",
       y = "Lag-one autocorrelation", x = "") +
  theme_minimal()



####Skewness
skewness.avg.all<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="Average"),"skewness"]
names(skewness.avg.all)<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="Average"),"CodGen"]
skewness.avg.all<-skewness.avg.all[intersec.ids]


skewness.aic.all<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="AIC"),"skewness"]
names(skewness.aic.all)<-merged.res[which(merged.res$CodGen %in% intersec.ids & merged.res$Method=="AIC"),"CodGen"]
skewness.aic.all<-skewness.aic.all[intersec.ids]



db.cor.sk<-data.frame(ID=c(names(skewness.avg.all),names(skewness.avg.all[ids.95.avg]),names(skewness.avg.all[ids.90.avg]),names(skewness.aic.all),names(skewness.aic.all[ids.95.best]),names(skewness.aic.all[ids.90.best])),
                        logvar=c(skewness.avg.all,skewness.avg.all[ids.95.avg],skewness.avg.all[ids.90.avg],skewness.aic.all,skewness.aic.all[ids.95.best],skewness.aic.all[ids.90.best]),
                        Method=c(rep("Average",length(c(names(skewness.avg.all),names(skewness.avg.all[ids.95.avg]),names(skewness.avg.all[ids.90.avg])))),
                                 rep("AIC",length(c(names(skewness.aic.all),names(skewness.aic.all[ids.95.best]),names(skewness.aic.all[ids.90.best]))))),
                        Data=c(rep("All",length(names(skewness.avg.all))), rep("95%_AIC_avg",length(names(skewness.avg.all[ids.95.avg]))), rep("90%_AIC_avg",length(names(skewness.avg.all[ids.90.avg]))), rep("All",length(names(skewness.avg.all))),rep("95%_AIC_best",length(names(skewness.avg.all[ids.95.best]))),rep("90%_AIC_best",length(names(skewness.avg.all[ids.90.best]))))
)

# Combine Method and Data into a group label
data <- db.cor.sk %>%
  mutate(Group = paste(Method, Data, sep = "_"))

# Pivot data to wide format
pivot_data <- data %>%
  select(ID, Group, logvar) %>%
  pivot_wider(names_from = Group, values_from = logvar)

# Get group names
group_names <- colnames(pivot_data)[-1]  # Exclude 'ID'

# Initialize an empty matrix for Kendall's tau
tau_matrix <- matrix(NA, nrow = length(group_names), ncol = length(group_names))
rownames(tau_matrix) <- group_names
colnames(tau_matrix) <- group_names

# Fill the matrix with Kendall's tau values
for (i in 1:(length(group_names))) {
  for (j in i:length(group_names)) {
    if (i == j) {
      tau_matrix[i, j] <- 1  # Correlation of a group with itself
    } else {
      # Select data for the pair
      pair_data <- pivot_data %>%
        select(all_of(group_names[i]), all_of(group_names[j])) %>%
        na.omit()
      
      if (nrow(pair_data) > 1) {
        # Calculate Kendall's tau
        tau_value <- cor(pair_data[[1]], pair_data[[2]], method = "kendall")
        tau_matrix[i, j] <- tau_value
        tau_matrix[j, i] <- tau_value  # Symmetric matrix
      }
    }
  }
}

# Melt the matrix into long format for ggplot2
tau_long <- melt(tau_matrix, varnames = c("Group1", "Group2"), value.name = "Kendall_Tau")

# Plot the heatmap
ggplot(tau_long, aes(x = Group1, y = Group2, fill = Kendall_Tau)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "blue",       # For negative correlation
    mid = "white",      # Neutral (zero correlation)
    high = "red",       # For positive correlation
    midpoint = 0,       # Set zero correlation to white
    limits = c(-1, 1),  # Define the scale limits
    na.value = "grey90" # Color for NA values
  ) +
  geom_text(aes(label = round(Kendall_Tau, 2)), color = "black", size = 4) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(size = 10),
        panel.grid = element_blank()) +
  labs(title = "Kendall's Tau Correlation Matrix Skewness", x = "Group", y = "Group", fill = "Tau")


# Kendall's tau correlation
kendall_corr_sk.all <- cor.test(skewness.aic.all,skewness.avg.all, method = "kendall")

kendall_corr_sk.all

kendall_corr_sk.95 <- cor.test(skewness.aic.all[ids.95.avg], skewness.avg.all[ids.95.avg], method = "kendall")

kendall_corr_sk.95


plot_data <- data.frame(CodGen=rep(names(skewness.avg.all[ids.95.avg]),2),sk=c(skewness.avg.all[ids.95.avg],skewness.aic.all[ids.95.avg]),Method=c(rep("Average",length(skewness.avg.all[ids.95.avg])),rep("AIC",length(skewness.aic.all[ids.95.avg]))))

# Paired line plot
ggplot(plot_data, aes(x = Method, y = sk, group = CodGen)) +
  geom_line(alpha = 0.8, color = "gray") +
  geom_point(aes(color = Method), size = 3) +
  labs(title = "Paired Comparison of Skewness: Best Average vs Ensemble",
       y = "Skewness", x = "") +
  theme_minimal()


##########
#### Uncertainty Quantification
######


uniq.ids<-unique(out.indID.df$CodGen)

IC.models<-lapply(seq_along(uniq.ids), function(i) {
  
  print(paste(i, "out", length(out.indID$models_weight)))
  
  IDs<-uniq.ids[i]
  
  weight<-"weight_AIC"
  prod<-"Produccion_Final_Dia"
  
  tmp.out<-out.indID.df[which(out.indID.df$CodGen%in%IDs),]
  
  predicted_mean<-mean(tmp.out[,weight])
  lower_bound <- quantile(tmp.out[,weight],probs = 0.025)
  upper_bound <- quantile(tmp.out[,weight],probs = 0.975)
  
  tmp.out$lw_bound<-lower_bound
  
  tmp.out$up_bound<-upper_bound
  
  return(tmp.out)
  
})

IC.models <- do.call(rbind, IC.models)
IC.models <- as.data.frame(IC.models)


coverage <- mean(IC.models$Produccion_Final_Dia >= IC.models$lw_bound & IC.models$Produccion_Final_Dia <= IC.models$up_bound)
print(paste("Coverage Probability:", coverage))



ggplot(IC.models[which(IC.models$CodGen=="DGM150276"),], aes(x = DIM_2)) +
  geom_line(aes(y = Produccion_Final_Dia, color = "Observed"), size = 1) +
  geom_line(aes(y = weight_AIC, color = "Predicted"), size = 1) +
  geom_ribbon(aes(ymin = lw_bound, ymax = up_bound), fill = "grey80", alpha = 0.5) +
  scale_color_manual(values = c("Observed" = "blue", "Predicted" = "red")) +
  labs(title = "Observed vs Predicted Daily Milk Production",
       x = "Day", y = "Milk Yield", color = "Legend") +
  theme_minimal()


# Plot using ggplot2
ggplot(IC.models[which(IC.models$CodGen=="DGM150276"),], aes(x = DIM_2)) +
  # Observed values (blue line)
  geom_point(aes(y = Produccion_Final_Dia, color = "Observed"), size = 1) +
  
  # Predicted values (red line)
  geom_line(aes(y = weight_AIC, color = "Predicted"), size = 1) +
  
  # Confidence interval (grey dashed lines)
  geom_line(aes(y = lw_bound, color = "lower 95% CI"), linetype = "dashed", size = 0.8) +
  geom_line(aes(y = up_bound, color = "upper 95% CI"), linetype = "dashed", size = 0.8) +
  
  # Customize colors manually
  scale_color_manual(values = c("Observed" = "blue", "Predicted" = "red", "lower 95% CI" = "grey","upper 95% CI" = "green")) +
  
  # Labels and theme
  labs(title = "Observed vs Predicted with 95% Confidence Interval",
       x = "Index",
       y = "Values",
       color = "Legend") +
  
  theme_minimal() +  # Clean theme
  theme(legend.position = "top")


fit.models.95<-fit.models[which(fit.models$ID%in%ids.95.avg),]

fit.models.95$lw_bound_weight_pred_best<-fit.models.95$pred_best- 1.96 * (sd(fit.models.95$pred_best) / sqrt(length(fit.models.95$pred_best)))

fit.models.95$up_bound_weight_pred_best<-fit.models.95$pred_best + 1.96 * (sd(fit.models.95$pred_best) / sqrt(length(fit.models.95$pred_best)))

coverage <- mean(fit.models.95$Prod_real >= fit.models.95$lw_bound_weight_pred_best & fit.models.95$Prod_real <= fit.models.95$up_bound_weight_pred_best)
print(paste("Coverage Probability:", coverage))




###########
####RMSE
###########
# Define a function to compute CV and RMSE for cubspline
compute_metrics_BestModels <- function(models, df_weights, df, id,mod) {
  
  # Access the sublist of models for the given ID
  models_for_id <- models[[id]]
  
  mod.best<-mod
  
  if (is.null(models_for_id)) {
    stop(paste("No models available for ID:", id))
  }
  
  # Access the best model
  sel.model <- models_for_id[[mod.best]]
  
  if (!is.null(sel.model)) {
    
    # Predict using the best model  
    pred.val <- predict(sel.model)
    
    # Calculate the differences between observed and predicted values
    differences <- df$Produccion_Final_Dia - pred.val
    
    mean_y <- mean(df$Produccion_Final_Dia)
    
    # Root Mean Squared Error (RMSE)
    rmse <- sqrt(mean(differences^2))
    
    return(data.frame(ID=id,RMSE = rmse))
    
  }
  
}

# Define a function to compute CV and RMSE
compute_metrics <- function(df,df_weights,id,weight) {
  # Calculate the differences between observed and predicted values
  differences <- df$Produccion_Final_Dia - df[,weight]
  
  mean_y <- mean(df$Produccion_Final_Dia)
  
  # Root Mean Squared Error (RMSE)
  rmse <- sqrt(mean(differences^2))
  
  return(data.frame(ID=id,RMSE = rmse))
}


list.prod<-out.indID$production

ids<-unique(names(out.indID$production))

ids.85.best<-db.quantil[which(db.quantil$avg_best=="Best_ind" & db.quantil$quant>0.85 & db.quantil$quant<0.9),"ID"]

ids.80.best<-db.quantil[which(db.quantil$avg_best=="Best_ind" & db.quantil$quant==0.80),"ID"]

ids.85.avg<-db.quantil[which(db.quantil$avg_best=="Average" & db.quantil$quant>0.85 & db.quantil$quant<0.9),"ID"]

ids.80.avg<-db.quantil[which(db.quantil$avg_best=="Average" & db.quantil$quant==0.80),"ID"]


list_ids<-list(All=ids,
               best_95=ids[which(ids%in%ids.95.best)],
               best_90=ids[which(ids%in%ids.90.best)],
               avg_95=ids[which(ids%in%ids.95.avg)],
               avg_90=ids[which(ids%in%ids.90.avg)],
               best_85=ids[which(ids%in%ids.85.best)],
               best_80=ids[which(ids%in%ids.80.best)],
               avg_85=ids[which(ids%in%ids.85.avg)],
               avg_80=ids[which(ids%in%ids.80.avg)]
               )



merged.rme.final<-NULL
for(k in 1:length(list_ids)){

  print(k)
  
##########
####weight_AIC
#########

# Apply the function to each data frame in the list
out.AIC <- lapply(seq_along(list_ids[[k]]), function(i) {
  id <- list_ids[[k]][i]
  compute_metrics(df_weights = out.indID$models_weight[[i]],
                  df = out.indID$production[[i]],
                  id = id,
                  weight="weight_AIC")
})

# Convert the results to a data frame
out.AIC <- do.call(rbind, out.AIC)
out.AIC <- as.data.frame(out.AIC)
# Reset rownames to a default sequence
out.AIC$Approach<-"weight_AIC"
out.AIC$RMSE<-as.numeric(out.AIC$RMSE)



##########
####weight_BIC
#########

# Apply the function to each data frame in the list
out.BIC <- lapply(seq_along(list_ids[[k]]), function(i) {
  id <- list_ids[[k]][i]
  compute_metrics(df_weights = out.indID$models_weight[[i]],
                  df = out.indID$production[[i]],
                  id = id,
                  weight="weight_BIC")
})

# Convert the results to a data frame
out.BIC <- do.call(rbind, out.BIC)
out.BIC <- as.data.frame(out.BIC)
# Reset rownames to a default sequence
out.BIC$Approach<-"weight_BIC"
out.BIC$RMSE<-as.numeric(out.BIC$RMSE)


##########
####weight_SMA
#########

# Apply the function to each data frame in the list
out.SMA <- lapply(seq_along(list_ids[[k]]), function(i) {
  id <- list_ids[[k]][i]
  
  df<-out.indID$production[[id]]
  
  differences <- df$Produccion_Final_Dia - df[,"SMA"]
  
  mean_y <- mean(df$Produccion_Final_Dia)
  
  # Root Mean Squared Error (RMSE)
  rmse <- sqrt(mean(differences^2))
  
  return(data.frame(ID=id,RMSE = rmse))
  
})
# Convert the results to a data frame
out.SMA <- do.call(rbind, out.SMA)
out.SMA <- as.data.frame(out.SMA)
# Reset rownames to a default sequence
out.SMA$Approach<-"SMA"
out.SMA$RMSE<-as.numeric(out.SMA$RMSE)

##########
####weight_BMA
#########

# Apply the function to each data frame in the list
out.BMA <- lapply(seq_along(list_ids[[k]]), function(i) {
  id <- list_ids[[k]][i]
  
  df<-out.indID$production[[id]]
  
  differences <- df$Produccion_Final_Dia - df[,"weight_BAM"]
  
  mean_y <- mean(df$Produccion_Final_Dia)
  
  # Root Mean Squared Error (RMSE)
  rmse <- sqrt(mean(differences^2))
  
  return(data.frame(ID=id,RMSE = rmse))
  
})

# Convert the results to a data frame
out.BMA <- do.call(rbind, out.BMA)
out.BMA <- as.data.frame(out.BMA)
# Reset rownames to a default sequence
out.BMA$Approach<-"weight_BAM"
out.BMA$RMSE<-as.numeric(out.BMA$RMSE)


##########
####weight_CosSquared
#########

# Apply the function to each data frame in the list
out.CosSquared <- lapply(seq_along(list_ids[[k]]), function(i) {
  id <- list_ids[[k]][i]
  
  df<-out.indID$production[[id]]
  
  differences <- df$Produccion_Final_Dia - df[,"weight_CosSquared"]
  
  mean_y <- mean(df$Produccion_Final_Dia)
  
  # Root Mean Squared Error (RMSE)
  rmse <- sqrt(mean(differences^2))
  
  return(data.frame(ID=id,RMSE = rmse))
  
})

# Convert the results to a data frame
out.CosSquared <- do.call(rbind, out.CosSquared)
out.CosSquared <- as.data.frame(out.CosSquared)
# Reset rownames to a default sequence
out.CosSquared$Approach<-"weight_CosSquared"
out.CosSquared$RMSE<-as.numeric(out.CosSquared$RMSE)

##########
####BAM_Het
#########

# Apply the function to each data frame in the list
out.BAM_Het<- lapply(seq_along(list_ids[[k]]), function(i) {
  id <- list_ids[[k]][i]
  
  df<-out.indID$production[[id]]
  
  differences <- df$Produccion_Final_Dia - df[,"BAM_Het"]
  
  mean_y <- mean(df$Produccion_Final_Dia)
  
  # Root Mean Squared Error (RMSE)
  rmse <- sqrt(mean(differences^2))
  
  return(data.frame(ID=id,RMSE = rmse))
  
})

# Convert the results to a data frame
out.BAM_Het <- do.call(rbind, out.BAM_Het)
out.BAM_Het <- as.data.frame(out.BAM_Het)
# Reset rownames to a default sequence
out.BAM_Het$Approach<-"BAM_Het"
out.BAM_Het$RMSE<-as.numeric(out.BAM_Het$RMSE)



#########
####cubsplin5
#########

# Assume you have a vector of IDs corresponding to the data frames

mod_id<-"cubsplin5"

out.cubsplin5<-NULL
for(mod in mod_id){
  
  # Apply the function to each data frame in the list
  out.variation.CosSquared.1 <- lapply(seq_along(list_ids[[k]]), function(i) {
    id <- list_ids[[k]][i]
    compute_metrics_BestModels(models = out.indID$converged_models,
                               df_weights = out.indID$models_weight[[id]],
                               df = out.indID$production[[id]],
                               id = id,
                               mod=mod)
  })
  
  # Convert the results to a data frame
  out.variation.CosSquared.1 <- do.call(rbind, out.variation.CosSquared.1)
  out.variation.CosSquared.1 <- as.data.frame(out.variation.CosSquared.1)
  
  out.cubsplin5<-rbind(out.variation.CosSquared.1,out.cubsplin5)
  
}

out.cubsplin5<-as.data.frame(out.cubsplin5)
out.cubsplin5$Approach<-"cubsplin5"
out.cubsplin5$RMSE<-as.numeric(out.cubsplin5$RMSE)

#######
###Best individual
######

out.best.individual<-lapply(seq_along(seq_along(list_ids[[k]])), function(i) {
  
  id <- list_ids[[k]][i]
  
  tmp.weight<-out.indID$models_weight[[id]]
  
  tmp.weight<-tmp.weight[order(tmp.weight$AIC),]
  
  sel.model<-tmp.weight$Model[1]
  
  sel.model.fit<-out.indID$converged_models[[id]]
  
  sel.model.fit<-sel.model.fit[[sel.model]]
  
  pred.vals<-predict(sel.model.fit)

  df<-out.indID$production[[id]]
  
  differences <- df$Produccion_Final_Dia - pred.vals
  
  mean_y <- mean(df$Produccion_Final_Dia)
  
  # Root Mean Squared Error (RMSE)
  rmse <- sqrt(mean(differences^2))
  
  return(data.frame(ID=id,RMSE = rmse))
  
})
out.best.individual <- do.call(rbind, out.best.individual)
out.best.individual <- as.data.frame(out.best.individual)
out.best.individual$Approach<-"best_ind"
out.best.individual$RMSE<-as.numeric(out.best.individual$RMSE)


merged.rme<-rbind(out.AIC,out.BIC,out.BMA,out.SMA,out.BAM_Het,out.CosSquared, out.cubsplin5, out.best.individual)
merged.rme$RMSE<-as.numeric(merged.rme$RMSE)
merged.rme$Group<-names(list_ids[k])


merged.rme.final<-rbind(merged.rme.final,merged.rme)

}



merged.rme.final$Approach<-factor(merged.rme.final$Approach, levels = c("cubsplin5","best_ind","SMA","weight_AIC", "weight_BIC","weight_BAM","BAM_Het","weight_CosSquared"))

ggplot(merged.rme.final, aes(x = factor(Approach), y = RMSE, fill=Approach)) + facet_wrap(~Group)+
  geom_boxplot(position = position_dodge(width = 0.75), outlier.shape = NA) +
  labs(x = "Method", y = "RMSE", title = "") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")  + 
  theme(axis.text.x = element_text(size=5), axis.text.y = element_text(size=15), axis.title = element_text(size=15),strip.text = element_text(size = 14, face = "bold"))


aggregate(merged.rme.final$RMSE,by=list(paste(merged.rme.final$Approach,"-",merged.rme.final$Group)),FUN=mean)







###Best model in average cubsplin5
best.avg.model<-lapply(seq_along(out.indID$models_weight), function(i) {
  
  tmp.weight<-out.indID$models_weight[[i]]
  
  tmp.weight<-tmp.weight[which(tmp.weight$Model=="qntReg"),"AIC"]
  
  out.weight<-data.frame(Model="cubsplin5",AIC=tmp.weight,ID=names(out.indID$models_weight[i]))
  
})
best.avg.model <- do.call(rbind, best.avg.model)
best.avg.model <- as.data.frame(best.avg.model)
